{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "import train\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['land', 'excavate', 'shoal', ['sound', 'salvage', 'dredge', 'survey', 'sidle'], 'dredge']\n",
      "['volcano', 'quiescent', 'talent', ['imperious', 'hyperbolical', 'oblique', 'latent', 'pliant'], 'latent']\n",
      "['style', 'flamboyant', 'behavior', ['brazen', 'lofty', 'volatile', 'insolent', 'sassy'], 'brazen']\n",
      "['direct', 'confront', 'oblique', ['unsettle', 'incite', 'sidle', 'stymie', 'flourish'], 'sidle']\n",
      "['beforehand', 'trepidation', 'afterwards', ['bravado', 'decadence', 'hyperbole', 'foolhardy', 'rue'], 'rue']\n",
      "['person', 'odious', 'action', ['unsettling', 'imperious', 'heinous', 'lofty', 'haughty'], 'heinous']\n",
      "['naughtiness', 'permit', 'misbehavior', ['dredge', 'confront', 'pique', 'countenance', 'stymie'], 'countenance']\n",
      "['speech', 'hyperbole', 'behavior', ['trepidation', 'quiescence', 'bravado', 'pique', 'parsimony'], 'bravado']\n",
      "['emotional', 'resistance', 'physical', ['cadaver', 'survey', 'conflagration', 'decadence', 'friction'], 'friction']\n",
      "['interest', 'rouse', 'curiosity', ['assuage', 'nettle', 'dredge', 'rue', 'pique'], 'pique']\n",
      "['mien', 'haughty', 'countenance', ['flamboyant', 'imperious', 'befuddled', 'canny', 'brazen'], 'imperious']\n",
      "['threateningly', 'brandish', 'flamboyantly', ['confront', 'flaunt', 'fan', 'incite', 'garner'], 'flaunt']\n",
      "['latent', 'possibility', 'hidden', ['cache', 'ire', 'hovel', 'visage', 'urchin'], 'cache']\n",
      "['travel', 'blocked', 'attempt', ['rued', 'incited', 'salvage', 'stymied', 'unsettled'], 'stymied']\n",
      "['salesman', 'canny', 'businesswoman', ['entrepreneurial', 'prolific', 'shrewd', 'haughty', 'frugal'], 'shrewd']\n",
      "['brave', 'reckless', 'frugal', ['prolific', 'audacious', 'foolhardy', 'poor', 'parsimonious'], 'parsimonious']\n",
      "['personality', 'pliant', 'behavior', ['lofty', 'insolent', 'cooperative', 'volatile', 'popular'], 'cooperative']\n"
     ]
    }
   ],
   "source": [
    "questions = {\n",
    "}\n",
    "\n",
    "questions[1]=preprocess.string_to_analogy(\"land:excavate::shoal:_,sound salvage dredge survey sidle,dredge\")\n",
    "#questions[2]=preprocess.string_to_analogy(\"sword:brandish::_:_,\")\n",
    "questions[3]=preprocess.string_to_analogy(\"volcano:quiescent::talent:_,imperious hyperbolical oblique latent pliant,latent\")\n",
    "questions[4]=preprocess.string_to_analogy(\"style:flamboyant::behavior:_,brazen lofty volatile insolent sassy,brazen\")\n",
    "questions[5]=preprocess.string_to_analogy(\"direct:confront::oblique:_,unsettle incite sidle stymie flourish,sidle\")\n",
    "questions[6]=preprocess.string_to_analogy(\"beforehand:trepidation::afterwards:_,bravado decadence hyperbole foolhardy rue,rue\")\n",
    "questions[7]=preprocess.string_to_analogy(\"person:odious::action:_,unsettling imperious heinous lofty haughty,heinous\")\n",
    "questions[8]=preprocess.string_to_analogy(\"naughtiness:permit::misbehavior:_,dredge confront pique countenance stymie,countenance\")\n",
    "questions[9]=preprocess.string_to_analogy(\"speech:hyperbole::behavior:_,trepidation quiescence bravado pique parsimony,bravado\")\n",
    "questions[10]=preprocess.string_to_analogy(\"emotional:resistance::physical:_,cadaver survey conflagration decadence friction,friction\")\n",
    "questions[11]=preprocess.string_to_analogy(\"interest:rouse::curiosity:_,assuage nettle dredge rue pique,pique\")\n",
    "questions[12]=preprocess.string_to_analogy(\"mien:haughty::countenance:_, flamboyant imperious befuddled canny brazen,imperious\")\n",
    "questions[13]=preprocess.string_to_analogy(\"threateningly:brandish::flamboyantly:_,confront flaunt fan incite garner,flaunt\")\n",
    "#questions[14]=preprocess.string_to_analogy\n",
    "questions[15]=preprocess.string_to_analogy(\"latent:possibility::hidden:_,cache ire hovel visage urchin,cache\")\n",
    "#questions[16]=preprocess.string_to_analogy\n",
    "questions[17]=preprocess.string_to_analogy(\"travel:blocked::attempt:_,rued incited salvage stymied unsettled,stymied\")\n",
    "questions[18]=preprocess.string_to_analogy(\"salesman:canny::businesswoman:_,entrepreneurial prolific shrewd haughty frugal,shrewd\")\n",
    "questions[19]=preprocess.string_to_analogy(\"brave:reckless::frugal:_,prolific audacious foolhardy poor parsimonious,parsimonious\")\n",
    "questions[20]=preprocess.string_to_analogy(\"personality:pliant::behavior:_,lofty insolent cooperative volatile popular,cooperative\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "incorrect = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training from ./GoogleNews-vectors-negative300.bin\n",
      "Model trained\n"
     ]
    }
   ],
   "source": [
    "file = './GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "print(f\"Training from {file}\")\n",
    "model = KeyedVectors.load_word2vec_format(file, binary=True)\n",
    "model.init_sims(replace=True)\n",
    "print(\"Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. land:excavate::shoal:_____?\n",
      "\tsound\n",
      "\tsalvage\n",
      "\tdredge\n",
      "\tsurvey\n",
      "\tsidle\n",
      "Predictions are [('snailfish', 0.8898302912712097), ('dredge', 0.8836666941642761), ('oarfish', 0.8802536725997925), ('divers', 0.8777430653572083), ('finback_whale', 0.8762484192848206)]\n",
      "\n",
      "Answer: dredge\n",
      "land:excavate::shoal:dredge\n",
      "Answer is correct.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3. volcano:quiescent::talent:_____?\n",
      "\timperious\n",
      "\thyperbolical\n",
      "\toblique\n",
      "\tlatent\n",
      "\tpliant\n",
      "Predictions are [('talented', 0.8820160031318665), ('supremely_talented', 0.845802903175354), ('immensely_talented', 0.8376045227050781), ('bare_cupboard', 0.818310022354126), ('brainpower', 0.8174195885658264)]\n",
      "\n",
      "Answer: pliant\n",
      "volcano:quiescent::talent:pliant\n",
      "Answer is incorrect, intended answer was latent.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4. style:flamboyant::behavior:_____?\n",
      "\tbrazen\n",
      "\tlofty\n",
      "\tvolatile\n",
      "\tinsolent\n",
      "\tsassy\n",
      "Predictions are [('antisocial', 0.9095085263252258), ('behaviors', 0.8813495635986328), ('sexually_predatory', 0.878678023815155), ('Tealeaf_CEM_solutions', 0.8783724904060364), ('behaving', 0.8763563632965088)]\n",
      "\n",
      "Answer: insolent\n",
      "style:flamboyant::behavior:insolent\n",
      "Answer is incorrect, intended answer was brazen.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5. direct:confront::oblique:_____?\n",
      "\tunsettle\n",
      "\tincite\n",
      "\tsidle\n",
      "\tstymie\n",
      "\tflourish\n",
      "Predictions are [('confronting', 0.9246678352355957), ('hamstring', 0.9207090735435486), ('shoulder', 0.8851784467697144), ('Hamstring', 0.8840982913970947), ('rib_cage_muscle', 0.8832801580429077)]\n",
      "\n",
      "Answer: unsettle\n",
      "direct:confront::oblique:unsettle\n",
      "Answer is incorrect, intended answer was sidle.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6. beforehand:trepidation::afterwards:_____?\n",
      "\tbravado\n",
      "\tdecadence\n",
      "\thyperbole\n",
      "\tfoolhardy\n",
      "\true\n",
      "Predictions are [('elation', 0.8968633413314819), ('sadness', 0.8729554414749146), ('jubilation', 0.8724989295005798), ('joy', 0.8600959777832031), ('mixed_emotions', 0.8475418090820312)]\n",
      "\n",
      "Answer: bravado\n",
      "beforehand:trepidation::afterwards:bravado\n",
      "Answer is incorrect, intended answer was rue.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "7. person:odious::action:_____?\n",
      "\tunsettling\n",
      "\timperious\n",
      "\theinous\n",
      "\tlofty\n",
      "\thaughty\n",
      "Predictions are [('dastardly', 0.9021337032318115), ('valiant_rearguard', 0.8563077449798584), ('punitive_measures', 0.8557600975036621), ('warpath', 0.855116069316864), ('bloodthirsty', 0.8534868359565735)]\n",
      "\n",
      "Answer: heinous\n",
      "person:odious::action:heinous\n",
      "Answer is correct.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "8. naughtiness:permit::misbehavior:_____?\n",
      "\tdredge\n",
      "\tconfront\n",
      "\tpique\n",
      "\tcountenance\n",
      "\tstymie\n",
      "Predictions are [('permits', 0.9060388207435608), ('pesticide_applicator_license', 0.8603391647338867), ('Permits', 0.8416693210601807), ('unsuccessfully_petitioned', 0.8355711698532104), ('Permit', 0.8305276036262512)]\n",
      "\n",
      "Answer: dredge\n",
      "naughtiness:permit::misbehavior:dredge\n",
      "Answer is incorrect, intended answer was countenance.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "9. speech:hyperbole::behavior:_____?\n",
      "\ttrepidation\n",
      "\tquiescence\n",
      "\tbravado\n",
      "\tpique\n",
      "\tparsimony\n",
      "Predictions are [('tendancies', 0.9296635985374451), ('behavour', 0.9235352873802185), ('nosiness', 0.9226434230804443), ('stupidity', 0.9038366675376892), ('idiocy', 0.9016435146331787)]\n",
      "\n",
      "Answer: bravado\n",
      "speech:hyperbole::behavior:bravado\n",
      "Answer is correct.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10. emotional:resistance::physical:_____?\n",
      "\tcadaver\n",
      "\tsurvey\n",
      "\tconflagration\n",
      "\tdecadence\n",
      "\tfriction\n",
      "Predictions are [('resistence', 0.9449889063835144), ('resistances', 0.8935425281524658), ('Resistance', 0.8725492358207703), ('Fibonacci_resistance', 0.8267849087715149), ('##mohm', 0.8091259598731995)]\n",
      "\n",
      "Answer: friction\n",
      "emotional:resistance::physical:friction\n",
      "Answer is correct.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "11. interest:rouse::curiosity:_____?\n",
      "\tassuage\n",
      "\tnettle\n",
      "\tdredge\n",
      "\true\n",
      "\tpique\n",
      "Predictions are [('roused', 0.9943220019340515), ('awaken', 0.9312834739685059), ('tryptophan_induced', 0.9003074169158936), ('amuse', 0.89892578125), ('wakens', 0.8975121378898621)]\n",
      "\n",
      "Answer: assuage\n",
      "interest:rouse::curiosity:assuage\n",
      "Answer is incorrect, intended answer was pique.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12. mien:haughty::countenance:_____?\n",
      "\tflamboyant\n",
      "\timperious\n",
      "\tbefuddled\n",
      "\tcanny\n",
      "\tbrazen\n",
      "Predictions are [('acquiesce', 0.8687853217124939), ('craven', 0.8326225280761719), ('disdainful', 0.8316997289657593), ('contemptuous', 0.826097846031189), ('feckless', 0.8251597881317139)]\n",
      "\n",
      "Answer: brazen\n",
      "mien:haughty::countenance:brazen\n",
      "Answer is incorrect, intended answer was imperious.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13. threateningly:brandish::flamboyantly:_____?\n",
      "\tconfront\n",
      "\tflaunt\n",
      "\tfan\n",
      "\tincite\n",
      "\tgarner\n",
      "Predictions are [('flaunt', 0.9030855298042297), ('flashy', 0.8423847556114197), ('gaudier', 0.8273518681526184), ('boast', 0.8245977163314819), ('gaudy', 0.8192916512489319)]\n",
      "\n",
      "Answer: flaunt\n",
      "threateningly:brandish::flamboyantly:flaunt\n",
      "Answer is correct.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "15. latent:possibility::hidden:_____?\n",
      "\tcache\n",
      "\tire\n",
      "\thovel\n",
      "\tvisage\n",
      "\turchin\n",
      "Predictions are [('possiblity', 0.8462435603141785), ('possibilty', 0.7963617444038391), ('possible', 0.7622435092926025), ('booby_trapping', 0.7448225021362305), ('allege_Liascos', 0.7400875687599182)]\n",
      "\n",
      "Answer: ire\n",
      "latent:possibility::hidden:ire\n",
      "Answer is incorrect, intended answer was cache.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "17. travel:blocked::attempt:_____?\n",
      "\trued\n",
      "\tincited\n",
      "\tsalvage\n",
      "\tstymied\n",
      "\tunsettled\n",
      "Predictions are [('attempts', 1.0998374223709106), ('attempted', 1.0325729846954346), ('unsucessful', 1.0102449655532837), ('unsuccessful', 0.9842193126678467), ('failed', 0.9600614905357361)]\n",
      "\n",
      "Answer: stymied\n",
      "travel:blocked::attempt:stymied\n",
      "Answer is correct.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18. salesman:canny::businesswoman:_____?\n",
      "\tentrepreneurial\n",
      "\tprolific\n",
      "\tshrewd\n",
      "\thaughty\n",
      "\tfrugal\n",
      "Predictions are [('shrewd', 0.9446521997451782), ('astute', 0.9057926535606384), ('strong_willed', 0.8679912686347961), ('headstrong', 0.8672139048576355), ('feisty', 0.8582713007926941)]\n",
      "\n",
      "Answer: shrewd\n",
      "salesman:canny::businesswoman:shrewd\n",
      "Answer is correct.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "19. brave:reckless::frugal:_____?\n",
      "\tprolific\n",
      "\taudacious\n",
      "\tfoolhardy\n",
      "\tpoor\n",
      "\tparsimonious\n",
      "Predictions are [('spendthrift', 0.9912363886833191), ('overspending', 0.9814909100532532), ('profligate_spending', 0.9471275210380554), ('profligate', 0.9302635788917542), ('extravagance', 0.9285930395126343)]\n",
      "\n",
      "Answer: parsimonious\n",
      "brave:reckless::frugal:parsimonious\n",
      "Answer is correct.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "20. personality:pliant::behavior:_____?\n",
      "\tlofty\n",
      "\tinsolent\n",
      "\tcooperative\n",
      "\tvolatile\n",
      "\tpopular\n",
      "Predictions are [('recalcitrant', 0.863889217376709), ('depredations', 0.8370040655136108), ('behaving', 0.8357617855072021), ('supine', 0.8292211294174194), ('predations', 0.8283452987670898)]\n",
      "\n",
      "Answer: insolent\n",
      "personality:pliant::behavior:insolent\n",
      "Answer is incorrect, intended answer was cooperative.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question_number in questions:\n",
    "    data = questions[question_number] \n",
    "    print(f\"{question_number}. {data[0]}:{data[1]}::{data[2]}:_____?\")\n",
    "    for answer in data[3]:\n",
    "        print(f\"\\t{answer}\")\n",
    "\n",
    "    ref = model.most_similar_cosmul(positive=[data[1],data[2]], negative=[data[0]], topn=5)\n",
    "    print(f\"Predictions are {ref}\")\n",
    "\n",
    "    for word in data[3]:\n",
    "        if word not in model.vocab:\n",
    "            data[3].remove(word)\n",
    "\n",
    "    submission = model.most_similar_to_given(ref[0][0], data[3])\n",
    "    print()\n",
    "    print(f\"Answer: {submission}\")\n",
    "    print(f\"{data[0]}:{data[1]}::{data[2]}:{submission}\")\n",
    "    if submission ==  data[4]:\n",
    "        print(\"Answer is correct.\")\n",
    "        correct.append(question_number)\n",
    "    else:\n",
    "        print(f\"Answer is incorrect, intended answer was {data[4]}.\")\n",
    "        incorrect.append(question_number)\n",
    "\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model scored 8 out of 17!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model scored {len(correct)} out of {len(correct)+len(incorrect)}!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('talent', 0.472327321767807),\n",
       " ('quiescent', 0.44346877932548523),\n",
       " ('talented', 0.4036876857280731),\n",
       " ('supremely_talented', 0.3586314916610718),\n",
       " ('immensely_talented', 0.3515331745147705)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = model[questions[3][1]] + model[questions[3][2]] - model[questions[3][0]]\n",
    "model.similar_by_vector(sum, topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43346363"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_similarity([\"shoal\"],[\"dredge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-faa3a2436e2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKDTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mANNSearch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mword2idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0midx2word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "class ANNSearch:\n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    data = []\n",
    "\n",
    "    def __init__(self, model):\n",
    "        for counter, key in enumerate(model.vocab.keys()):\n",
    "            self.data.append(model[key])\n",
    "            self.word2idx[key] = counter\n",
    "            self.idx2word[counter] = key\n",
    "\n",
    "        # leaf_size is a hyperparameter\n",
    "        self.data = np.array(self.data)\n",
    "        self.tree = KDTree(self.data, leaf_size=100)\n",
    "        \n",
    "    def search_by_vector(self, v, k=10):\n",
    "        dists, inds = self.tree.query([v], k)\n",
    "        return zip(dists[0], [self.idx2word[idx] for idx in inds[0]])\n",
    "\n",
    "    def search(self, query, k=10):\n",
    "        vector = self.data[self.word2idx[query]]\n",
    "        return self.search_by_vector(vector, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
